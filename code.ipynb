{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a97dbf9",
   "metadata": {},
   "source": [
    "# 000 One-time creation of excel sheet with quarterly GDP Joined on (imputation to be done in Excel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26541cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"unemployment_rate_AR.xls\") #unemployment-only data (with date)\n",
    "df_GDP = pd.read_excel(\"A191RL1Q225SBEA.xls\") #gdp quarterly-only data (with date)\n",
    "df_left = df.merge(df_GDP, how = 'left', on = 'observation_date') \n",
    "df_left.to_excel(\"gdp_merged.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a6966",
   "metadata": {},
   "source": [
    "# 000 Mounting of dataframe with updated gdp and flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aea65ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_UR = pd.read_excel(\"unemployment_rate_AR.xls\") #unemployment-only data (with date)\n",
    "df_GDP_flows = pd.read_excel(\"Labor_Force_Flows.xls\", sheet_name = 1) # labor force flows and new gdp growth data (with date)\n",
    "df_GDP_flows.dropna(inplace = True)\n",
    "df_right = df_UR.merge(df_GDP_flows, how = 'right', left_on = 'observation_date', right_on = 'DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f9edf",
   "metadata": {},
   "source": [
    "# 001 AR(6) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f194e595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022844253571604106\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import math \n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#df = pd.read_excel(\"unemployment_rate_AR.xls\") #option to use old data \n",
    "df = df_right #from the above box (updated data)\n",
    "result_arr = np.zeros((800,2)) #to store predictions and actual values \n",
    "index = 0 #for indexing the above array\n",
    "\n",
    "#The below loop will, from data point number 100 to the end, train up to that point, generate a prediction, and then store\n",
    "#the actual value at that time step. The starting value will change based on the dataset used..\n",
    "for i in range(100, len(df)):\n",
    "    train_data = df[\"UNRATE_20221202\"][:i] \n",
    "    ar_model = AutoReg(train_data, lags = 6).fit()\n",
    "    pred = ar_model.forecast(1)\n",
    "    result_arr[index][0] = pred\n",
    "    result_arr[index][1] = df[\"UNRATE_20221202\"][i]\n",
    "    index = index + 1\n",
    "    \n",
    "RMSE = mean_squared_error(result_arr[:][1], result_arr[:][0], squared = False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7a6be",
   "metadata": {},
   "source": [
    "# 001 Naive Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e0b4741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0707106781186545\n"
     ]
    }
   ],
   "source": [
    "df = df_right #from the above box (updated data)\n",
    "index = 0\n",
    "#The below loop will, from data point number 100 to the end store the previous data point and the current data point\n",
    "for i in range(100, len(df)):\n",
    "    result_arr[index][0] = df[\"UNRATE_20221202\"][i-1]\n",
    "    result_arr[index][1] = df[\"UNRATE_20221202\"][i]\n",
    "    index = index + 1\n",
    "    \n",
    "RMSE = mean_squared_error(result_arr[:][1], result_arr[:][0], squared = False)\n",
    "print(RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf0b0a",
   "metadata": {},
   "source": [
    "# 001 Preprocess for LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5532295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import math \n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Other options - \n",
    "#Example Option A - old dataset\n",
    "#df_gdf_processed = pd.read_excel(\"gdp_merged.xls\")\n",
    "#selected = df_gdf_processed[['UNRATE_20221202','A191RL1Q225SBEA']]\n",
    "#Example Option B - old dataset with just employment \n",
    "#selected = df_gdf_processed[['UNRATE_20221202']]\n",
    "\n",
    "selected = df_right[['UNRATE_20221202','BBKMGDP_PCH']] #up to date dataset with just GDP \n",
    "\n",
    "#train-test split cutoff\n",
    "cutoff = math.floor(len(selected) * .8) \n",
    "selected_train = selected.iloc[0:cutoff,0:] \n",
    "selected_test = selected.iloc[cutoff:,0:]\n",
    "selected_test.reset_index(inplace = True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scale train inputs and targets\n",
    "sc_train_x = StandardScaler()\n",
    "selected_train_scaled_x = sc_train_x.fit_transform(selected_train)\n",
    "sc_train_y = StandardScaler()\n",
    "selected_train_scaled_y  = sc_train_y.fit_transform(selected_train[['UNRATE_20221202']])\n",
    "\n",
    "#develop train inputs and targets by looping (in each loop pick, as input, data at the previous 6 time-steps and \n",
    "#as output, the unemployment rate at the next time-step) until cutoff\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range (6, cutoff):\n",
    "    X_train.append(selected_train_scaled_x[i-6:i])\n",
    "    y_train.append(selected_train_scaled_y[i])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train_shaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8c3b4",
   "metadata": {},
   "source": [
    "# 002 Hyperparameter Optimized LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfe845a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prupi\\AppData\\Local\\Temp/ipykernel_17520/3448999342.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = model_builder)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 7ms/step - loss: 541.2485 - accuracy: 0.0163\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 453.6759 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 5ms/step - loss: 675.0013 - accuracy: 0.0000e+00\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 26.5608 - accuracy: 0.2258\n",
      "25/25 [==============================] - 4s 5ms/step - loss: 770.2026 - accuracy: 0.0122\n",
      "7/7 [==============================] - 1s 5ms/step - loss: 163.0813 - accuracy: 0.0164\n",
      "25/25 [==============================] - 4s 5ms/step - loss: 540.8605 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 932.8245 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 5ms/step - loss: 450.1869 - accuracy: 0.0163\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 685.2668 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 3s 5ms/step - loss: 483.2193 - accuracy: 0.0122\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 352.9386 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 5ms/step - loss: 572.6162 - accuracy: 0.0082\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 33.9706 - accuracy: 0.2258\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 665.2328 - accuracy: 0.0081\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 70.9301 - accuracy: 0.0164\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 442.1859 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 696.2123 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 373.7538 - accuracy: 0.0122\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 464.9018 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 426.5534 - accuracy: 0.0163\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 210.9083 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 493.1647 - accuracy: 0.0082\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 82.8736 - accuracy: 0.2258\n",
      "25/25 [==============================] - 3s 6ms/step - loss: 579.0326 - accuracy: 0.0081\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 44.7156 - accuracy: 0.0164\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 363.9533 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 579.7024 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 7ms/step - loss: 341.6530 - accuracy: 0.0081\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 392.4565 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 633.2757 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 744.1968 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 754.9685 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 62.4157 - accuracy: 0.0645 \n",
      "25/25 [==============================] - 4s 5ms/step - loss: 855.6594 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 287.7853 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 601.5291 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 1141.1785 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 3s 6ms/step - loss: 530.7827 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 983.3807 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 629.7244 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 740.4125 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 755.9445 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 62.0246 - accuracy: 0.0645 \n",
      "25/25 [==============================] - 4s 6ms/step - loss: 856.0316 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 287.6334 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 3s 6ms/step - loss: 601.0858 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 1139.9668 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 6ms/step - loss: 532.4656 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 5ms/step - loss: 986.3954 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 8ms/step - loss: 629.0249 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 739.1848 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 7ms/step - loss: 749.9183 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 62.9002 - accuracy: 0.0645 \n",
      "25/25 [==============================] - 4s 6ms/step - loss: 853.5318 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 288.1743 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 3s 6ms/step - loss: 602.6328 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 5ms/step - loss: 1144.6479 - accuracy: 0.0000e+00\n",
      "25/25 [==============================] - 4s 7ms/step - loss: 534.9068 - accuracy: 0.0041\n",
      "7/7 [==============================] - 1s 4ms/step - loss: 998.3651 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 613.4118 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 664.3113 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 713.8826 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 51.5754 - accuracy: 0.0645 \n",
      "10/10 [==============================] - 3s 7ms/step - loss: 828.9128 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 275.1013 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 6ms/step - loss: 580.0002 - accuracy: 0.0041\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x00000234F3373280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 1046.9751 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 518.1766 - accuracy: 0.0041\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000234F6B73D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 907.2562 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 8ms/step - loss: 589.7065 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 525.9992 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 671.8784 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 39.2615 - accuracy: 0.0645\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 790.3049 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 224.6208 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 8ms/step - loss: 547.1825 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 911.0562 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 12ms/step - loss: 496.6412 - accuracy: 0.0081\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 722.3130 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 8ms/step - loss: 568.5029 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 452.6520 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 652.8401 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 23.9135 - accuracy: 0.0645\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 756.6142 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 151.7661 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 526.1459 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 823.0021 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 472.8439 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 7ms/step - loss: 642.7276 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 6ms/step - loss: 637.7993 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 748.7935 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 6ms/step - loss: 755.6809 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 62.5770 - accuracy: 0.0645 \n",
      "10/10 [==============================] - 3s 9ms/step - loss: 852.1801 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 290.3418 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 602.0333 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 1144.8857 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 6ms/step - loss: 533.1008 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 8ms/step - loss: 997.2588 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 6ms/step - loss: 633.3255 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 744.7821 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 753.1169 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 62.8232 - accuracy: 0.0645 \n",
      "10/10 [==============================] - 3s 12ms/step - loss: 851.4211 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 7ms/step - loss: 288.6824 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 6ms/step - loss: 604.0934 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 1150.3856 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 6ms/step - loss: 533.8717 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 995.0266 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 635.2570 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 745.9356 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 752.7449 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 62.9238 - accuracy: 0.0645 \n",
      "10/10 [==============================] - 4s 8ms/step - loss: 856.3857 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 287.4515 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 3s 7ms/step - loss: 600.2921 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 1137.6473 - accuracy: 0.0000e+00\n",
      "10/10 [==============================] - 4s 7ms/step - loss: 532.8575 - accuracy: 0.0041\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 993.4404 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 8ms/step - loss: 621.6803 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 708.4238 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 4s 8ms/step - loss: 741.7515 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 59.4097 - accuracy: 0.0645\n",
      "5/5 [==============================] - 3s 7ms/step - loss: 842.1922 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 283.6764 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 6ms/step - loss: 594.6579 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 5ms/step - loss: 1109.0503 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 7ms/step - loss: 527.7332 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 7ms/step - loss: 956.4167 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 620.8948 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 6ms/step - loss: 691.5529 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 4s 9ms/step - loss: 735.3018 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 8ms/step - loss: 60.1620 - accuracy: 0.0645\n",
      "5/5 [==============================] - 3s 8ms/step - loss: 839.1132 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 5ms/step - loss: 278.2604 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 4s 9ms/step - loss: 590.3251 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 6ms/step - loss: 1070.4608 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 523.7719 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 8ms/step - loss: 919.0068 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 609.5333 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 640.3237 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 720.6266 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 58.4005 - accuracy: 0.0645\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 826.4175 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 278.1963 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 582.2866 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 10ms/step - loss: 995.1928 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 507.9169 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 6ms/step - loss: 757.6500 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 8ms/step - loss: 633.0245 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 6ms/step - loss: 742.9249 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 749.0799 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 63.9032 - accuracy: 0.0645\n",
      "5/5 [==============================] - 3s 8ms/step - loss: 855.3421 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 8ms/step - loss: 287.4730 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 11ms/step - loss: 603.0351 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 1147.3582 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 8ms/step - loss: 534.5004 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 996.7422 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 11ms/step - loss: 633.9138 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 745.2571 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 754.5142 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 5ms/step - loss: 62.7557 - accuracy: 0.0645\n",
      "5/5 [==============================] - 4s 10ms/step - loss: 855.1285 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 287.8715 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 603.3071 - accuracy: 0.0041 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step - loss: 1147.2393 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 4s 9ms/step - loss: 532.1818 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 8ms/step - loss: 987.4359 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 633.9233 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 744.6041 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 751.7185 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 9ms/step - loss: 63.0334 - accuracy: 0.0645\n",
      "5/5 [==============================] - 4s 9ms/step - loss: 855.7700 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 4ms/step - loss: 287.5121 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 601.8771 - accuracy: 0.0041 \n",
      "2/2 [==============================] - 1s 7ms/step - loss: 1142.5695 - accuracy: 0.0000e+00\n",
      "5/5 [==============================] - 4s 10ms/step - loss: 533.6566 - accuracy: 0.0041\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 993.3821 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 625.4457 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 710.9081 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 8ms/step - loss: 747.8872 - accuracy: 0.0041 \n",
      "1/1 [==============================] - 1s 752ms/step - loss: 61.2360 - accuracy: 0.0645\n",
      "4/4 [==============================] - 3s 8ms/step - loss: 847.9739 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 284.0018 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 599.6782 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 1119.1102 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 530.0926 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 967.2961 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 630.0442 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 720.6011 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 744.7738 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 61.0416 - accuracy: 0.0645\n",
      "4/4 [==============================] - 3s 8ms/step - loss: 849.7002 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 282.0822 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 9ms/step - loss: 593.1941 - accuracy: 0.0041 \n",
      "1/1 [==============================] - 1s 707ms/step - loss: 1064.8444 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 7ms/step - loss: 527.1861 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 922.5401 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 12ms/step - loss: 614.5656 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 1s/step - loss: 643.5164 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 11ms/step - loss: 741.2699 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 62.6433 - accuracy: 0.0645\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 839.4191 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 282.4459 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 10ms/step - loss: 589.7421 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 1014.8750 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 525.5644 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 871.2142 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 8ms/step - loss: 631.9636 - accuracy: 0.0041 \n",
      "1/1 [==============================] - 1s 764ms/step - loss: 743.1779 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 8ms/step - loss: 755.4274 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 1s/step - loss: 62.0941 - accuracy: 0.0645\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 855.5741 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 1s/step - loss: 287.4472 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 8ms/step - loss: 605.0443 - accuracy: 0.0041 \n",
      "1/1 [==============================] - 1s 836ms/step - loss: 1153.6000 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 533.5367 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 993.2143 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 10ms/step - loss: 635.6918 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 746.1153 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 11ms/step - loss: 755.2751 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 62.4406 - accuracy: 0.0645\n",
      "4/4 [==============================] - 4s 10ms/step - loss: 854.0801 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 288.0504 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 602.6880 - accuracy: 0.0041 \n",
      "1/1 [==============================] - 1s 797ms/step - loss: 1146.4833 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 9ms/step - loss: 533.9278 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 1s/step - loss: 995.4969 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 631.4827 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 743.3126 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 12ms/step - loss: 752.8967 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 62.7905 - accuracy: 0.0645\n",
      "4/4 [==============================] - 4s 9ms/step - loss: 857.5845 - accuracy: 0.0041 \n",
      "1/1 [==============================] - 1s 720ms/step - loss: 287.4395 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 3s 10ms/step - loss: 602.1105 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 1143.5515 - accuracy: 0.0000e+00\n",
      "4/4 [==============================] - 4s 10ms/step - loss: 532.9386 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 991.0108 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 8ms/step - loss: 628.2657 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 725.6706 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 752.1245 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 61.7134 - accuracy: 0.0645\n",
      "3/3 [==============================] - 3s 9ms/step - loss: 853.1848 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 284.5718 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_train_function.<locals>.train_function at 0x00000234FF7CFCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 3s 9ms/step - loss: 599.2489 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 1121.4921 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x00000234F33738B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 11ms/step - loss: 532.1671 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 980.0006 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 625.9443 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 714.0173 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 746.3925 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 62.3809 - accuracy: 0.0645\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 842.8942 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 285.0574 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 595.2710 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1084.5652 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 531.0855 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 950.0637 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 628.1731 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 718.5937 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 743.4930 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 62.5641 - accuracy: 0.0645\n",
      "3/3 [==============================] - 4s 11ms/step - loss: 841.8356 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 285.0048 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 4s 12ms/step - loss: 594.2584 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 1053.8682 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 530.6038 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 937.8838 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 4s 10ms/step - loss: 634.0693 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 744.5972 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 752.1504 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 62.6382 - accuracy: 0.0645\n",
      "3/3 [==============================] - 3s 7ms/step - loss: 853.4057 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 288.6204 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 4s 10ms/step - loss: 600.8403 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 769ms/step - loss: 1140.0336 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 532.0643 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 987.0115 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 4s 13ms/step - loss: 632.5335 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 744.2839 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 754.6369 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 62.4623 - accuracy: 0.0645\n",
      "3/3 [==============================] - 4s 12ms/step - loss: 853.9207 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 288.1148 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 604.2603 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 1151.3408 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 533.7228 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 996.3763 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 13ms/step - loss: 633.8466 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 743.6808 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 753.2991 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 62.6354 - accuracy: 0.0645\n",
      "3/3 [==============================] - 4s 12ms/step - loss: 858.2917 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 286.6590 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 4s 12ms/step - loss: 604.3961 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 1151.3717 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 4s 13ms/step - loss: 532.5729 - accuracy: 0.0041\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 992.2833 - accuracy: 0.0000e+00\n",
      "31/31 [==============================] - 3s 5ms/step - loss: 624.6744 - accuracy: 0.0130\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import keras\n",
    "import sklearn\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#each individual model\n",
    "def model_builder(hp_unit, hp_learning_rate):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = hp_unit, return_sequences = True, input_shape = (6,2))) #This will change depending on df used\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units = hp_unit))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate), loss = 'mean_squared_error', metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn = model_builder)\n",
    "\n",
    "#grid search \n",
    "params = {'batch_size':[10,25,50,75,100], \n",
    "          'nb_epoch': [100],\n",
    "          'hp_unit':[10, 20, 30], \n",
    "          'hp_learning_rate': [1e-2,1e-4]}\n",
    "gs = GridSearchCV(estimator = model, param_grid = params, cv = 5)\n",
    "gs = gs.fit(X_train_shaped, y_train)\n",
    "\n",
    "#return the best estimator\n",
    "model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28ca3c",
   "metadata": {},
   "source": [
    "# 002 Non-Hyperparameter Optimized LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cba2df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 5s 461ms/step - loss: 0.8374 - val_loss: 0.8327\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6606 - val_loss: 0.5909\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4987 - val_loss: 0.3733\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3361 - val_loss: 0.1819\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2246 - val_loss: 0.0485\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1364 - val_loss: 0.0412\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0945 - val_loss: 0.1947\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1044 - val_loss: 0.3897\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1135 - val_loss: 0.4133\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1061 - val_loss: 0.3011\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0937 - val_loss: 0.1918\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0808 - val_loss: 0.1215\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0832 - val_loss: 0.0852\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0855 - val_loss: 0.0713\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0786 - val_loss: 0.0662\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0789 - val_loss: 0.0677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234e2739c70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import keras\n",
    "\n",
    "#define the neural net\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (6,2))) #This will also change depending on df used\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "#fit the model with early stopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "model.fit(X_train_shaped, y_train, epochs = 100, batch_size = 100, validation_split = .2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a779bfc",
   "metadata": {},
   "source": [
    "# 003 LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e11af8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.256271148082802"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tack on the the last 6 data points from the train since those correspond to the first test target and then transform\n",
    "df_train_last = selected_train[-6:] \n",
    "full_df = pd.concat((df_train_last, selected_test), axis = 0)[[\"UNRATE_20221202\",'BBKMGDP_PCH']]\n",
    "#full_df = pd.concat((df_train_last, selected_test), axis = 0)[[\"UNRATE_20221202\"]] #option to just use the unemployment rate \n",
    "full_df = sc_train_x.transform(full_df)\n",
    "\n",
    "#generate test input by looping consecutive 6's in the input until the last data point\n",
    "x_test = []\n",
    "for i in range(6, len(selected) - cutoff + 6):\n",
    "    x_test.append(full_df[i-6:i])\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#predict and inverse scale since the output is trained off of scaled targets\n",
    "y_test = model.predict(x_test)\n",
    "y_final_pred = sc_train_y.inverse_transform(y_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(selected_test['UNRATE_20221202'],y_final_pred, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7e540",
   "metadata": {},
   "source": [
    "# 001 VAR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "086d5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07416993731232889\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "import statistics\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Different input options - \n",
    "#Example Option A - the full updated dataset\n",
    "#selected = df_right[['UNRATE_20221202','BBKMGDP_PCH','pUtoE', 'pNLtoE' , 'pEtoU', 'pNLtoU', 'pEtoNL', 'pUtoNL']]\n",
    "#Example Option B - GDP + Unemployment from updated dataset\n",
    "#selected = df_right[['UNRATE_20221202','BBKMGDP_PCH']] \n",
    "df_gdp_processed = pd.read_excel(\"gdp_merged.xls\")\n",
    "selected = df_gdp_processed[['UNRATE_20221202','A191RL1Q225SBEA']]\n",
    "\n",
    "result_arr = np.zeros((800,2)) #array to store the predictions and the actual value\n",
    "index = 0 #indexing the above result array \n",
    "\n",
    "#The below loop will, from data point number 100 to the end, train up to that point, generate a prediction, and then store\n",
    "#the actual value at that time step. The starting value will change based on the dataframe used. \n",
    "for i in range(605\n",
    "               , len(selected)):\n",
    "    train_data = selected[:i]\n",
    "    var = VAR(selected)\n",
    "    \n",
    "    #this section checks the different measurement errors and selected the lag parameter that corresponds to the most minimums\n",
    "    order = var.select_order()\n",
    "    selected_order = statistics.mode([order.selected_orders['aic'], order.selected_orders['bic'], \n",
    "                            order.selected_orders['hqic'], order.selected_orders['fpe']])\n",
    "    final_model = var.fit(selected_order)\n",
    "    \n",
    "    pred = final_model.forecast(train_data.values[-selected_order:],1)[0][0]\n",
    "    result_arr[index][0] = pred\n",
    "    result_arr[index][1] = selected[\"UNRATE_20221202\"][i]\n",
    "    index = index + 1\n",
    "    \n",
    "RMSE = mean_squared_error(result_arr[:][1], result_arr[:][0], squared = False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d6ddc",
   "metadata": {},
   "source": [
    "895-cutoff\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
